{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae407d1",
   "metadata": {},
   "source": [
    "# Test LSTM Food Freshness Model\n",
    "\n",
    "This notebook loads the trained ONNX model and tests it with sample sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38940453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement onnxruntime (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python314\\python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for onnxruntime\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed\n",
    "!pip install onnxruntime pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f092502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import onnxruntime as ort\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f44f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "ONNX_MODEL_PATH = \"lstm_food_freshness.onnx\"\n",
    "DATA_FILE = \"food_freshness_dataset.csv\"\n",
    "SEQUENCE_LENGTH = 10  # Must match training configuration\n",
    "\n",
    "# Sensor columns (3 analog sensors)\n",
    "SENSOR_COLUMNS = ['MQ135_Analog', 'MQ3_Analog', 'MiCS5524_Analog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d757281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load ONNX Model ---\n",
    "print(f\"Loading ONNX model from {ONNX_MODEL_PATH}...\")\n",
    "ort_session = ort.InferenceSession(ONNX_MODEL_PATH)\n",
    "\n",
    "# Get model input details\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Input name: {input_name}\")\n",
    "print(f\"Output name: {output_name}\")\n",
    "print(f\"Expected input shape: (batch_size, {SEQUENCE_LENGTH}, {len(SENSOR_COLUMNS)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135cd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to Create Sequences ---\n",
    "def create_test_sequence(data, start_idx, seq_length=10):\n",
    "    \"\"\"\n",
    "    Create a single sequence from the data starting at start_idx.\n",
    "    Returns shape (1, seq_length, num_features) for model input.\n",
    "    \"\"\"\n",
    "    if start_idx + seq_length > len(data):\n",
    "        raise ValueError(f\"Not enough data. Need {seq_length} samples from index {start_idx}\")\n",
    "\n",
    "    sequence = data[start_idx:start_idx + seq_length]\n",
    "    # Reshape to (1, seq_length, num_features) for batch size of 1\n",
    "    return sequence.reshape(1, seq_length, -1).astype(np.float32)\n",
    "\n",
    "# --- Function to Make Prediction (Dual Outputs) ---\n",
    "def predict(sequence):\n",
    "    \"\"\"\n",
    "    Make prediction using ONNX model.\n",
    "    Returns classification probability, class label, and RSL hours.\n",
    "    \"\"\"\n",
    "    ort_inputs = {input_name: sequence}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "    # Output 1: Classification\n",
    "    classification_prob = ort_outputs[0][0][0]\n",
    "    classification_pred = 1 if classification_prob > 0.5 else 0\n",
    "    \n",
    "    # Output 2: RSL\n",
    "    rsl_hours = max(0, ort_outputs[1][0][0])  # Ensure non-negative\n",
    "    \n",
    "    return classification_prob, classification_pred, rsl_hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900bd4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare Scaler (fit on all data for testing purposes) ---\n",
    "X = df[SENSOR_COLUMNS].values\n",
    "y = df['Output'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"\\nData scaled. Shape: {X_scaled.shape}\")\n",
    "print(f\"Feature means: {scaler.mean_}\")\n",
    "print(f\"Feature std devs: {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd15cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to Create Sequences ---\n",
    "def create_test_sequence(data, start_idx, seq_length=10):\n",
    "    \"\"\"\n",
    "    Create a single sequence from the data starting at start_idx.\n",
    "    Returns shape (1, seq_length, num_features) for model input.\n",
    "    \"\"\"\n",
    "    if start_idx + seq_length > len(data):\n",
    "        raise ValueError(f\"Not enough data. Need {seq_length} samples from index {start_idx}\")\n",
    "    \n",
    "    sequence = data[start_idx:start_idx + seq_length]\n",
    "    # Reshape to (1, seq_length, num_features) for batch size of 1\n",
    "    return sequence.reshape(1, seq_length, -1).astype(np.float32)\n",
    "\n",
    "# --- Function to Make Prediction ---\n",
    "def predict(sequence):\n",
    "    \"\"\"\n",
    "    Make prediction using ONNX model.\n",
    "    Returns probability and class label.\n",
    "    \"\"\"\n",
    "    ort_inputs = {input_name: sequence}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "    probability = ort_outputs[0][0][0]\n",
    "    prediction = 1 if probability > 0.5 else 0\n",
    "    return probability, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a772f8",
   "metadata": {},
   "source": [
    "## Test with Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TEST 1: Random samples from dataset (Dual Output) ---\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 1: Testing with random samples from dataset (showing dual outputs)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "num_tests = 5\n",
    "random_indices = np.random.choice(len(df) - sequence_length, num_tests, replace=False)\n",
    "\n",
    "for i, idx in enumerate(random_indices, 1):\n",
    "    # Get the actual label for this sequence (label at the end of sequence)\n",
    "    actual_class = df.iloc[idx + sequence_length - 1]['Output']\n",
    "    actual_rsl = df.iloc[idx + sequence_length - 1]['RSL_Hours']\n",
    "\n",
    "    # Create sequence from scaled features\n",
    "    sequence = create_test_sequence(features_scaled, idx, sequence_length)\n",
    "\n",
    "    # Get prediction\n",
    "    prob, pred_class, pred_rsl = predict(sequence)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n--- Test {i} (Index {idx}) ---\")\n",
    "    print(f\"Last 3 sensor values in sequence:\")\n",
    "    print(f\"  MQ135: {df.iloc[idx+sequence_length-1]['MQ135_Analog']:.0f}\")\n",
    "    print(f\"  MQ3:   {df.iloc[idx+sequence_length-1]['MQ3_Analog']:.0f}\")\n",
    "    print(f\"  MiCS:  {df.iloc[idx+sequence_length-1]['MiCS5524_Analog']:.0f}\")\n",
    "    print(f\"\\nClassification:\")\n",
    "    print(f\"  Actual:     {'Fresh (1)' if actual_class == 1 else 'Bad (0)'}\")\n",
    "    print(f\"  Predicted:  {'Fresh (1)' if pred_class == 1 else 'Bad (0)'}\")\n",
    "    print(f\"  Confidence: {prob:.4f}\")\n",
    "    print(f\"  Status:     {'✓ CORRECT' if pred_class == actual_class else '✗ WRONG'}\")\n",
    "    print(f\"\\nRemaining Shelf Life:\")\n",
    "    print(f\"  Actual:     {actual_rsl:.1f} hours\")\n",
    "    print(f\"  Predicted:  {pred_rsl:.1f} hours\")\n",
    "    print(f\"  Error:      {abs(pred_rsl - actual_rsl):.1f} hours\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e9280",
   "metadata": {},
   "source": [
    "## Test with Custom Sensor Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TEST 2: Custom Sensor Values (Dual Output) ---\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 2: Testing with custom sensor values (showing dual outputs)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define test scenarios\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"name\": \"Very Fresh Food\",\n",
    "        \"values\": (150, 120, 180),\n",
    "        \"description\": \"All sensors in fresh range\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Slightly Fresh Food\",\n",
    "        \"values\": (300, 280, 320),\n",
    "        \"description\": \"Sensors near upper fresh range\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Borderline Food\",\n",
    "        \"values\": (400, 380, 420),\n",
    "        \"description\": \"Sensors at threshold\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Spoiled Food\",\n",
    "        \"values\": (700, 650, 720),\n",
    "        \"description\": \"All sensors indicating spoilage\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Very Spoiled Food\",\n",
    "        \"values\": (950, 900, 980),\n",
    "        \"description\": \"Sensors at maximum spoilage\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"\\n--- {scenario['name']} ---\")\n",
    "    print(f\"Description: {scenario['description']}\")\n",
    "    print(f\"Sensor Values: MQ135={scenario['values'][0]}, MQ3={scenario['values'][1]}, MiCS={scenario['values'][2]}\")\n",
    "\n",
    "    # Create a sequence with the same values repeated\n",
    "    custom_values = np.array([scenario['values']] * sequence_length)\n",
    "    custom_scaled = scaler.transform(custom_values)\n",
    "    sequence = custom_scaled.reshape(1, sequence_length, -1).astype(np.float32)\n",
    "\n",
    "    # Get prediction\n",
    "    prob, pred_class, pred_rsl = predict(sequence)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nClassification:\")\n",
    "    print(f\"  Predicted:  {'Fresh (1)' if pred_class == 1 else 'Bad (0)'}\")\n",
    "    print(f\"  Confidence: {prob:.4f}\")\n",
    "    print(f\"\\nRemaining Shelf Life:\")\n",
    "    print(f\"  Predicted:  {pred_rsl:.1f} hours\")\n",
    "    print(f\"  Status:     {'Expected: Long shelf life' if pred_class == 1 else 'Expected: Short/No shelf life'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e1260",
   "metadata": {},
   "source": [
    "## Visualize Predictions on Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TEST 3: Batch Testing (Dual Output) ---\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST 3: Batch testing on test set (showing dual outputs)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select a random batch of sequences for testing\n",
    "batch_size = 100\n",
    "start_indices = np.random.choice(len(df) - sequence_length, batch_size, replace=False)\n",
    "\n",
    "classification_correct = 0\n",
    "classification_probs = []\n",
    "classification_actuals = []\n",
    "classification_preds = []\n",
    "\n",
    "rsl_errors = []\n",
    "rsl_actuals = []\n",
    "rsl_preds = []\n",
    "\n",
    "for idx in start_indices:\n",
    "    # Get actual values\n",
    "    actual_class = df.iloc[idx + sequence_length - 1]['Output']\n",
    "    actual_rsl = df.iloc[idx + sequence_length - 1]['RSL_Hours']\n",
    "\n",
    "    # Create sequence and predict\n",
    "    sequence = create_test_sequence(features_scaled, idx, sequence_length)\n",
    "    prob, pred_class, pred_rsl = predict(sequence)\n",
    "\n",
    "    # Track classification metrics\n",
    "    classification_probs.append(prob)\n",
    "    classification_actuals.append(actual_class)\n",
    "    classification_preds.append(pred_class)\n",
    "    if pred_class == actual_class:\n",
    "        classification_correct += 1\n",
    "\n",
    "    # Track RSL metrics\n",
    "    rsl_actuals.append(actual_rsl)\n",
    "    rsl_preds.append(pred_rsl)\n",
    "    rsl_errors.append(abs(pred_rsl - actual_rsl))\n",
    "\n",
    "# Calculate metrics\n",
    "classification_accuracy = (classification_correct / batch_size) * 100\n",
    "rsl_mae = np.mean(rsl_errors)\n",
    "rsl_rmse = np.sqrt(np.mean(np.array(rsl_errors) ** 2))\n",
    "\n",
    "print(f\"\\nClassification Results:\")\n",
    "print(f\"  Batch Size: {batch_size}\")\n",
    "print(f\"  Accuracy:   {classification_accuracy:.2f}%\")\n",
    "print(f\"  Correct:    {classification_correct}/{batch_size}\")\n",
    "\n",
    "print(f\"\\nRSL Regression Results:\")\n",
    "print(f\"  MAE (Mean Absolute Error): {rsl_mae:.2f} hours\")\n",
    "print(f\"  RMSE (Root Mean Squared Error): {rsl_rmse:.2f} hours\")\n",
    "print(f\"  Min Error:  {min(rsl_errors):.2f} hours\")\n",
    "print(f\"  Max Error:  {max(rsl_errors):.2f} hours\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68014f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize Batch Results (Dual Output) ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Classification Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(classification_actuals, classification_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Classification Confusion Matrix')\n",
    "axes[0, 0].set_xlabel('Predicted')\n",
    "axes[0, 0].set_ylabel('Actual')\n",
    "axes[0, 0].set_xticklabels(['Bad (0)', 'Fresh (1)'])\n",
    "axes[0, 0].set_yticklabels(['Bad (0)', 'Fresh (1)'])\n",
    "\n",
    "# Plot 2: Classification Confidence Distribution\n",
    "axes[0, 1].hist(classification_probs, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Classification Confidence Distribution')\n",
    "axes[0, 1].set_xlabel('Confidence (Probability)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(x=0.5, color='r', linestyle='--', label='Threshold')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: RSL Actual vs Predicted\n",
    "axes[1, 0].scatter(rsl_actuals, rsl_preds, alpha=0.5)\n",
    "axes[1, 0].plot([0, max(rsl_actuals)], [0, max(rsl_actuals)], 'r--', label='Perfect Prediction')\n",
    "axes[1, 0].set_title('RSL: Actual vs Predicted')\n",
    "axes[1, 0].set_xlabel('Actual RSL (hours)')\n",
    "axes[1, 0].set_ylabel('Predicted RSL (hours)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: RSL Error Distribution\n",
    "axes[1, 1].hist(rsl_errors, bins=20, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 1].set_title('RSL Prediction Error Distribution')\n",
    "axes[1, 1].set_xlabel('Absolute Error (hours)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].axvline(x=rsl_mae, color='r', linestyle='--', label=f'MAE: {rsl_mae:.2f}h')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualizations complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dbbb47",
   "metadata": {},
   "source": [
    "## Test Single Reading Function (Arduino-like)\n",
    "\n",
    "This simulates how you would use the model with real-time sensor readings from Arduino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Arduino Simulation: SensorBuffer Class (Dual Output) ---\n",
    "class SensorBuffer:\n",
    "    \"\"\"\n",
    "    Simulates Arduino's rolling buffer for sensor readings.\n",
    "    Maintains last 10 readings for each sensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, buffer_size=10):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.mq135_buffer = []\n",
    "        self.mq3_buffer = []\n",
    "        self.mics_buffer = []\n",
    "        self.scaler = scaler  # Use the loaded scaler\n",
    "\n",
    "    def add_reading(self, mq135, mq3, mics):\n",
    "        \"\"\"Add new sensor readings to buffers\"\"\"\n",
    "        self.mq135_buffer.append(mq135)\n",
    "        self.mq3_buffer.append(mq3)\n",
    "        self.mics_buffer.append(mics)\n",
    "\n",
    "        # Keep only last buffer_size readings\n",
    "        if len(self.mq135_buffer) > self.buffer_size:\n",
    "            self.mq135_buffer.pop(0)\n",
    "            self.mq3_buffer.pop(0)\n",
    "            self.mics_buffer.pop(0)\n",
    "\n",
    "    def is_ready(self):\n",
    "        \"\"\"Check if buffer is full\"\"\"\n",
    "        return len(self.mq135_buffer) == self.buffer_size\n",
    "\n",
    "    def get_prediction(self):\n",
    "        \"\"\"Get prediction from current buffer (dual outputs)\"\"\"\n",
    "        if not self.is_ready():\n",
    "            return None, None, None\n",
    "\n",
    "        # Prepare sequence\n",
    "        sequence_data = np.column_stack([\n",
    "            self.mq135_buffer,\n",
    "            self.mq3_buffer,\n",
    "            self.mics_buffer\n",
    "        ])\n",
    "\n",
    "        # Scale the sequence\n",
    "        scaled_sequence = self.scaler.transform(sequence_data)\n",
    "\n",
    "        # Reshape for model input\n",
    "        sequence = scaled_sequence.reshape(1, self.buffer_size, -1).astype(np.float32)\n",
    "\n",
    "        # Get prediction\n",
    "        ort_inputs = {input_name: sequence}\n",
    "        ort_outputs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "        # Parse outputs\n",
    "        classification_prob = ort_outputs[0][0][0]\n",
    "        classification_pred = 1 if classification_prob > 0.5 else 0\n",
    "        rsl_hours = max(0, ort_outputs[1][0][0])\n",
    "\n",
    "        return classification_prob, classification_pred, rsl_hours\n",
    "\n",
    "\n",
    "# --- Simulate Arduino readings (Dual Output) ---\n",
    "print(\"=\" * 80)\n",
    "print(\"ARDUINO SIMULATION: Rolling buffer predictions (showing dual outputs)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "buffer = SensorBuffer(buffer_size=10)\n",
    "\n",
    "# Simulate 15 sensor readings (from fresh to spoiled)\n",
    "simulated_readings = [\n",
    "    (150, 130, 170),  # Very fresh\n",
    "    (160, 140, 180),\n",
    "    (170, 150, 190),\n",
    "    (200, 180, 220),\n",
    "    (250, 230, 270),\n",
    "    (300, 280, 320),  # Still fresh\n",
    "    (350, 330, 370),\n",
    "    (400, 380, 420),  # Borderline\n",
    "    (500, 480, 520),  # Getting bad\n",
    "    (600, 580, 620),  # Bad\n",
    "    (700, 680, 720),  # Very bad\n",
    "    (750, 730, 770),\n",
    "    (800, 780, 820),\n",
    "    (850, 830, 870),\n",
    "    (900, 880, 920),  # Extremely spoiled\n",
    "]\n",
    "\n",
    "for i, (mq135, mq3, mics) in enumerate(simulated_readings, 1):\n",
    "    buffer.add_reading(mq135, mq3, mics)\n",
    "\n",
    "    print(f\"\\nReading {i}: MQ135={mq135}, MQ3={mq3}, MiCS={mics}\")\n",
    "\n",
    "    if buffer.is_ready():\n",
    "        prob, pred_class, pred_rsl = buffer.get_prediction()\n",
    "        status = \"Fresh (1)\" if pred_class == 1 else \"Bad (0)\"\n",
    "        print(f\"  Classification: {status} (Confidence: {prob:.4f})\")\n",
    "        print(f\"  RSL: {pred_rsl:.1f} hours\")\n",
    "    else:\n",
    "        print(f\"  Buffer filling... ({len(buffer.mq135_buffer)}/{buffer.buffer_size} readings)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Arduino simulation complete!\")\n",
    "print(\"This demonstrates how the model would work on Arduino with rolling buffer.\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74454165",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The LSTM model has been successfully loaded and tested with:\n",
    "1. ✅ Random samples from the dataset\n",
    "2. ✅ Custom fresh food sensor values\n",
    "3. ✅ Custom spoiled food sensor values\n",
    "4. ✅ Batch predictions with visualization\n",
    "5. ✅ Real-time sensor buffer simulation (Arduino-like)\n",
    "\n",
    "The model is ready for deployment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
